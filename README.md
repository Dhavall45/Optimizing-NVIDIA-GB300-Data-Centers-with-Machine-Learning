# Optimizing-NVIDIA-GB300-Data-Centers-with-Machine-Learning
Unsupervised machine learning applied to NVIDIA GB300 GPU telemetry data for real-time power optimization in AI data centers. This project identifies power inefficiencies, anomalies, and synchronized GPU load patterns using KMeans, Isolation Forest, and PCA. Includes simulated time-series data, detailed EDA.
